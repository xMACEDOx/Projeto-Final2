# ğŸšŒ Projeto SPTrans Data Pipeline

### Monitoramento em Near Real-Time do Transporte PÃºblico de SÃ£o Paulo

![Python](https://img.shields.io/badge/Python-3.10-blue)
![Apache Spark](https://img.shields.io/badge/Spark-3.3-orange)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100-green)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)
![NiFi](https://img.shields.io/badge/Apache%20NiFi-Dataflow-success)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Database-informational)
![MinIO](https://img.shields.io/badge/MinIO-S3%20Storage-critical)

Este projeto implementa uma arquitetura moderna de dados para monitorar em tempo quase real o transporte pÃºblico de SÃ£o Paulo, utilizando a API Olho Vivo (SPTrans).
Toda a soluÃ§Ã£o foi construÃ­da com ferramentas open source, seguindo boas prÃ¡ticas de engenharia de dados, arquitetura Medallion (Bronze â†’ Silver â†’ Gold) e processamento distribuÃ­do.

O objetivo Ã© coletar, tratar, enriquecer e analisar informaÃ§Ãµes das principais linhas de Ã´nibus da cidade, gerando KPIs estratÃ©gicos como pontualidade, atraso mÃ©dio, headway e frota ativa â€” tudo exibido em um dashboard profissional no Power BI.

A soluÃ§Ã£o final demonstra habilidades completas de ponta a ponta em engenharia de dados, incluindo ingestÃ£o, transformaÃ§Ã£o, modelagem analÃ­tica e visualizaÃ§Ã£o.


## ğŸš€ Destaques do Projeto

IngestÃ£o automatizada com Apache NiFi, incluindo autenticaÃ§Ã£o dinÃ¢mica, manipulaÃ§Ã£o de cookies e coleta contÃ­nua da API Olho Vivo.

Data Lake estruturado em camadas Raw, Silver e Gold, armazenado no MinIO (S3 compatÃ­vel).

Processamento distribuÃ­do com Apache Spark (batch e streaming), incluindo:

Tratamento completo dos arquivos GTFS (linhas, viagens, paradas).

CÃ¡lculo e normalizaÃ§Ã£o da previsÃ£o de chegada das principais linhas por regiÃ£o.

Enriquecimento e consolidaÃ§Ã£o dos dados para anÃ¡lise operacional.

Modelo analÃ­tico (Camada Gold) armazenado no PostgreSQL, com KPIs prontos para consumo.

Dashboard interativo no Power BI com insights sobre desempenho, atrasos e operaÃ§Ã£o por linha e regiÃ£o.

Infra totalmente containerizada via Docker Compose, reproduzÃ­vel em qualquer mÃ¡quina.


# ARQUITETURA DO PROJETO

Cole aqui o diagrama da sua arquitetura atual


## ğŸ§  CompetÃªncias Demonstradas

Arquitetura Medallion (Bronze â†’ Silver â†’ Gold)

Data Lake com MinIO (S3)

IngestÃ£o automatizada com Apache NiFi

Processamento com Apache Spark (PySpark)

OrquestraÃ§Ã£o com Docker / Docker Compose

Modelagem analÃ­tica em PostgreSQL

VisualizaÃ§Ã£o de dados com Power BI

ManipulaÃ§Ã£o de APIs, GTFS e dados geoespaciais

Boas prÃ¡ticas de versionamento e organizaÃ§Ã£o de pipelines


## ğŸ¯ Objetivo

Criar uma infraestrutura completa de engenharia de dados capaz de:

Monitorar o transporte pÃºblico em tempo real

Calcular previsÃµes e mÃ©tricas avanÃ§adas de operaÃ§Ã£o

Disponibilizar indicadores confiÃ¡veis para tomada de decisÃ£o

Demonstrar domÃ­nio tÃ©cnico de ponta a ponta para ambientes corporativos.



## âš™ï¸ Como executar o projeto (passo a passo)

### 1.Clonar o repositÃ³rio
```
git clone https://github.com/<seu-usuario>/<seu-repo>.git
cd <seu-repo>
```


### 2 .Configurar variÃ¡veis de ambiente

Duplicar o arquivo .env (ou criar um) e ajustar:

Credenciais do PostgreSQL

Credenciais do MinIO

Token da API Olho Vivo (SPTrans), se estiver parametrizado

VersÃµes das imagens (MinIO, NiFi, Spark, etc.)



### 3 .Subir a infraestrutura com Docker Compose
```
docker compose up -d
```

Isso deve subir, pelo menos:

MinIO (armazenamento S3 compatÃ­vel)

NiFi (ingestÃ£o de dados)

Spark (processamento)

PostgreSQL (camada Gold / Data Mart)


### 4. Importar e iniciar o fluxo no NiFi

Acessar a UI do NiFi (ex.: http://localhost:8080/nifi)

Importar o fluxo (Projeto.json)

Iniciar os processadores responsÃ¡veis por:

AutenticaÃ§Ã£o na API Olho Vivo

Coleta de posiÃ§Ãµes dos veÃ­culos

IngestÃ£o dos arquivos GTFS

Escrita na camada Raw (MinIO)


### 5. Executar os notebooks Spark na ordem

Na pasta de notebooks (ou scripts):

0gtfs_silver.ipynb â€“ trata e estrutura os arquivos GTFS na camada Silver

1Previsao_Linhas2.ipynb â€“ calcula/organiza previsÃµes de chegada das principais linhas

2previsao_silver.ipynb â€“ normaliza a previsÃ£o em formato analÃ­tico

3nova_silver.ipynb â€“ faz o enriquecimento e junÃ§Ãµes finais

4processamento_batch_gold.ipynb â€“ grava as tabelas de KPIs na camada Gold (PostgreSQL)


### 6. Validar as tabelas no PostgreSQL

Conectar no banco e verificar se as tabelas / views de KPIs foram criadas

```
SELECT * FROM vw_kpi_dashboard LIMIT 10;
```


### 7. Abrir o dashboard no Power BI

Abrir o arquivo KPI'S.pbix

Configurar a conexÃ£o com o PostgreSQL (host, porta, database, usuÃ¡rio, senha)

Clicar em Atualizar para carregar os KPIs



## ğŸ—‚ï¸ ESTRUTURA DO REPOSITÃ“RIO
```
.
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ nifi/
â”‚   â””â”€â”€ Projeto.json
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 0gtfs_silver.ipynb
â”‚   â”œâ”€â”€ 1Previsao_Linhas2.ipynb
â”‚   â”œâ”€â”€ 2previsao_silver.ipynb
â”‚   â”œâ”€â”€ 3nova_silver.ipynb
â”‚   â””â”€â”€ 4processamento_batch_gold.ipynb
â”œâ”€â”€ powerbi/
â”‚   â””â”€â”€ KPI'S.pbix
â””â”€â”€ README.md
```

## ğŸ† RESULTADOS

Pipeline totalmente automatizada

KPIs estratÃ©gicos calculados

Dashboard profissional

Arquitetura replicÃ¡vel

DocumentaÃ§Ã£o completa

DemonstraÃ§Ã£o clara de habilidades avanÃ§adas de engenharia de dados


# ğŸŒ ARQUITETURA ESCALÃVEL â€” PRÃ“XIMOS PASSOS DO PROJETO

Esta seÃ§Ã£o Ã© para documentar como o projeto pode evoluir para uma soluÃ§Ã£o corporativa e altamente escalÃ¡vel.
Aqui estÃ£o alguns tÃ³picos jÃ¡ estruturados â€” vocÃª pode preencher cada um deles com seus futuros projetos.




























































































